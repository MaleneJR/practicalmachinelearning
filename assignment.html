<!DOCTYPE html>
  <html>
  <head>
<style type="text/css">
.knitr.inline {
  background-color: #f7f7f7;
  border:solid 1px #B0B0B0;
}
.error {
	font-weight: bold;
	color: #FF0000;
},
.warning {
	font-weight: bold;
}
.message {
	font-style: italic;
}
.source, .output, .warning, .error, .message {
	padding: 0em 1em;
  border:solid 1px #F7F7F7;
}
.source {
  background-color: #f5f5f5;
}
.rimage.left {
  text-align: left;
}
.rimage.right {
  text-align: right;
}
.rimage.center {
  text-align: center;
}
.hl.num {
  color: #AF0F91;
}
.hl.str {
  color: #317ECC;
}
.hl.com {
  color: #AD95AF;
  font-style: italic;
}
.hl.opt {
  color: #000000;
}
.hl.std {
  color: #585858;
}
.hl.kwa {
  color: #295F94;
  font-weight: bold;
}
.hl.kwb {
  color: #B05A65;
}
.hl.kwc {
  color: #55aa55;
}
.hl.kwd {
  color: #BC5A65;
  font-weight: bold;
}
</style>
  <title>Practical Machine Learning, march 2015</title>
  </head>
  <FONT face="verdana", size=2.5>
  <body>
  <h2> Practical Machine Learning </h2>
  <p> This exercise concerns exercise data from accelerometers on the belt, forearm, arm, and dumbell of six participants. They were asked to perform barbell lifts correctly and incorrectly in five different ways (<a href="http://groupware.les.inf.puc-rio.br/har">see data here</a>). The goal here is to predict the manner in which the exercise was performed, i.e. to predict the "classe" variable.<p>
  
 <h3>Load data</h3>



<div class="chunk" id="unnamed-chunk-2"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl kwd">library</span><span class="hl std">(caret)</span>
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: lattice
## Loading required package: ggplot2
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl kwd">library</span><span class="hl std">(doMC)</span>
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: foreach
## Loading required package: iterators
## Loading required package: parallel
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl std">test</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">read.csv</span><span class="hl std">(</span><span class="hl str">&quot;pml-testing.csv&quot;</span><span class="hl std">,</span> <span class="hl kwc">header</span><span class="hl std">=T)</span>
<span class="hl std">train</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">read.csv</span><span class="hl std">(</span><span class="hl str">&quot;pml-training.csv&quot;</span><span class="hl std">,</span> <span class="hl kwc">header</span><span class="hl std">=T)</span>
</pre></div>
</div></div>
 
<p>To find out which if any of the variables used for prediction has near zero variance, I use the nearZeroVar function. I remove these columns from the set of predictors as they may cause problems when resampling. Many of the predictors contain almost all missing values. I remove these columns as well. Furthermore there is an ID variable called X in the data set, which is completely correlated with the classe variable (see plot below). I therefore remove this as well.<p>
 
<div class="chunk" id="unnamed-chunk-3"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl com"># remove variables with near zero variance</span>
<span class="hl std">nearZeroVars</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">nearZeroVar</span><span class="hl std">(train)</span>
<span class="hl std">train</span> <span class="hl kwb">&lt;-</span> <span class="hl std">train[,</span><span class="hl opt">-</span><span class="hl std">nearZeroVars]</span>

<span class="hl com"># get number of NA rows in each column</span>
<span class="hl std">na.cols</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">apply</span><span class="hl std">(train,</span><span class="hl num">2</span><span class="hl std">,</span><span class="hl kwa">function</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">)</span> <span class="hl kwd">length</span><span class="hl std">(x[</span><span class="hl kwd">is.na</span><span class="hl std">(x)]))</span>
<span class="hl kwd">data.frame</span><span class="hl std">(na.cols)</span>
</pre></div>
<div class="output"><pre class="knitr r">##                          na.cols
## X                              0
## user_name                      0
## raw_timestamp_part_1           0
## raw_timestamp_part_2           0
## cvtd_timestamp                 0
## num_window                     0
## roll_belt                      0
## pitch_belt                     0
## yaw_belt                       0
## total_accel_belt               0
## max_roll_belt              19216
## max_picth_belt             19216
## min_roll_belt              19216
## min_pitch_belt             19216
## amplitude_roll_belt        19216
## amplitude_pitch_belt       19216
## var_total_accel_belt       19216
## avg_roll_belt              19216
## stddev_roll_belt           19216
## var_roll_belt              19216
## avg_pitch_belt             19216
## stddev_pitch_belt          19216
## var_pitch_belt             19216
## avg_yaw_belt               19216
## stddev_yaw_belt            19216
## var_yaw_belt               19216
## gyros_belt_x                   0
## gyros_belt_y                   0
## gyros_belt_z                   0
## accel_belt_x                   0
## accel_belt_y                   0
## accel_belt_z                   0
## magnet_belt_x                  0
## magnet_belt_y                  0
## magnet_belt_z                  0
## roll_arm                       0
## pitch_arm                      0
## yaw_arm                        0
## total_accel_arm                0
## var_accel_arm              19216
## gyros_arm_x                    0
## gyros_arm_y                    0
## gyros_arm_z                    0
## accel_arm_x                    0
## accel_arm_y                    0
## accel_arm_z                    0
## magnet_arm_x                   0
## magnet_arm_y                   0
## magnet_arm_z                   0
## max_picth_arm              19216
## max_yaw_arm                19216
## min_yaw_arm                19216
## amplitude_yaw_arm          19216
## roll_dumbbell                  0
## pitch_dumbbell                 0
## yaw_dumbbell                   0
## max_roll_dumbbell          19216
## max_picth_dumbbell         19216
## min_roll_dumbbell          19216
## min_pitch_dumbbell         19216
## amplitude_roll_dumbbell    19216
## amplitude_pitch_dumbbell   19216
## total_accel_dumbbell           0
## var_accel_dumbbell         19216
## avg_roll_dumbbell          19216
## stddev_roll_dumbbell       19216
## var_roll_dumbbell          19216
## avg_pitch_dumbbell         19216
## stddev_pitch_dumbbell      19216
## var_pitch_dumbbell         19216
## avg_yaw_dumbbell           19216
## stddev_yaw_dumbbell        19216
## var_yaw_dumbbell           19216
## gyros_dumbbell_x               0
## gyros_dumbbell_y               0
## gyros_dumbbell_z               0
## accel_dumbbell_x               0
## accel_dumbbell_y               0
## accel_dumbbell_z               0
## magnet_dumbbell_x              0
## magnet_dumbbell_y              0
## magnet_dumbbell_z              0
## roll_forearm                   0
## pitch_forearm                  0
## yaw_forearm                    0
## max_picth_forearm          19216
## min_pitch_forearm          19216
## amplitude_pitch_forearm    19216
## total_accel_forearm            0
## var_accel_forearm          19216
## gyros_forearm_x                0
## gyros_forearm_y                0
## gyros_forearm_z                0
## accel_forearm_x                0
## accel_forearm_y                0
## accel_forearm_z                0
## magnet_forearm_x               0
## magnet_forearm_y               0
## magnet_forearm_z               0
## classe                         0
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl com"># many of the variables have 19216 NA values out of a total of 19622 values; I remove these columns</span>
<span class="hl std">train</span> <span class="hl kwb">&lt;-</span> <span class="hl std">train[,</span><span class="hl opt">-</span><span class="hl kwd">which</span><span class="hl std">(na.cols</span><span class="hl opt">==</span><span class="hl num">19216</span><span class="hl std">)]</span>

<span class="hl com"># remove index variable</span>
<span class="hl kwd">qplot</span><span class="hl std">(X,classe,</span><span class="hl kwc">data</span><span class="hl std">=train)</span>
</pre></div>
</div><div class="rimage default"><img src="figure/unnamed-chunk-3-1.png" title="plot of chunk unnamed-chunk-3" alt="plot of chunk unnamed-chunk-3" class="plot" /></div><div class="rcode">
<div class="source"><pre class="knitr r"><span class="hl std">train</span><span class="hl opt">$</span><span class="hl std">X</span> <span class="hl kwb">&lt;-</span> <span class="hl kwa">NULL</span>

<span class="hl com"># look at the training data set</span>
<span class="hl kwd">str</span><span class="hl std">(train)</span>
</pre></div>
<div class="output"><pre class="knitr r">## 'data.frame':	19622 obs. of  58 variables:
##  $ user_name           : Factor w/ 6 levels &quot;adelmo&quot;,&quot;carlitos&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ raw_timestamp_part_1: int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2: int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp      : Factor w/ 20 levels &quot;02/12/2011 13:32&quot;,..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ num_window          : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt           : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt          : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt            : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt    : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ gyros_belt_x        : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y        : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z        : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x        : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y        : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z        : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x       : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y       : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z       : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm            : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm           : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm             : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm     : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ gyros_arm_x         : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y         : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z         : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x         : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y         : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z         : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x        : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y        : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z        : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ roll_dumbbell       : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell      : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell        : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ total_accel_dumbbell: int  37 37 37 37 37 37 37 37 37 37 ...
##  $ gyros_dumbbell_x    : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ gyros_dumbbell_y    : num  -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 ...
##  $ gyros_dumbbell_z    : num  0 0 0 -0.02 0 0 0 0 0 0 ...
##  $ accel_dumbbell_x    : int  -234 -233 -232 -232 -233 -234 -232 -234 -232 -235 ...
##  $ accel_dumbbell_y    : int  47 47 46 48 48 48 47 46 47 48 ...
##  $ accel_dumbbell_z    : int  -271 -269 -270 -269 -270 -269 -270 -272 -269 -270 ...
##  $ magnet_dumbbell_x   : int  -559 -555 -561 -552 -554 -558 -551 -555 -549 -558 ...
##  $ magnet_dumbbell_y   : int  293 296 298 303 292 294 295 300 292 291 ...
##  $ magnet_dumbbell_z   : num  -65 -64 -63 -60 -68 -66 -70 -74 -65 -69 ...
##  $ roll_forearm        : num  28.4 28.3 28.3 28.1 28 27.9 27.9 27.8 27.7 27.7 ...
##  $ pitch_forearm       : num  -63.9 -63.9 -63.9 -63.9 -63.9 -63.9 -63.9 -63.8 -63.8 -63.8 ...
##  $ yaw_forearm         : num  -153 -153 -152 -152 -152 -152 -152 -152 -152 -152 ...
##  $ total_accel_forearm : int  36 36 36 36 36 36 36 36 36 36 ...
##  $ gyros_forearm_x     : num  0.03 0.02 0.03 0.02 0.02 0.02 0.02 0.02 0.03 0.02 ...
##  $ gyros_forearm_y     : num  0 0 -0.02 -0.02 0 -0.02 0 -0.02 0 0 ...
##  $ gyros_forearm_z     : num  -0.02 -0.02 0 0 -0.02 -0.03 -0.02 0 -0.02 -0.02 ...
##  $ accel_forearm_x     : int  192 192 196 189 189 193 195 193 193 190 ...
##  $ accel_forearm_y     : int  203 203 204 206 206 203 205 205 204 205 ...
##  $ accel_forearm_z     : int  -215 -216 -213 -214 -214 -215 -215 -213 -214 -215 ...
##  $ magnet_forearm_x    : int  -17 -18 -18 -16 -17 -9 -18 -9 -16 -22 ...
##  $ magnet_forearm_y    : num  654 661 658 658 655 660 659 660 653 656 ...
##  $ magnet_forearm_z    : num  476 473 469 469 473 478 470 474 476 473 ...
##  $ classe              : Factor w/ 5 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
</pre></div>
</div></div>

<p>The default resampling method is the bootstrap for training the model, but I will use 10-fold cross validation with five replicates. This means that I split the data set into 10 parts, and leave one part out of the training procedure and test on this. I continue until all 10 parts have been left out. This is repeated five times. I set this with the trainControl function. I chose to fit a model using linear discriminant analysis (lda).<p>

<div class="chunk" id="unnamed-chunk-4"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl com"># fit models using five replicates of 10-fold cross validation</span>
<span class="hl std">ctrl</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">trainControl</span><span class="hl std">(</span><span class="hl kwc">method</span><span class="hl std">=</span><span class="hl str">&quot;repeatedcv&quot;</span><span class="hl std">,</span> <span class="hl kwc">repeats</span><span class="hl std">=</span><span class="hl num">5</span><span class="hl std">)</span>
<span class="hl std">lda.fit</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">train</span><span class="hl std">(classe</span> <span class="hl opt">~</span> <span class="hl std">.,</span> <span class="hl kwc">data</span><span class="hl std">=train,</span> <span class="hl kwc">method</span><span class="hl std">=</span><span class="hl str">&quot;lda&quot;</span><span class="hl std">,</span> <span class="hl kwc">trControl</span><span class="hl std">=ctrl,</span> <span class="hl kwc">verbose</span><span class="hl std">=F)</span>
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in lda.default(x, grouping, ...): variables are collinear
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl std">lda.fit</span>
</pre></div>
<div class="output"><pre class="knitr r">## Linear Discriminant Analysis 
## 
## 19622 samples
##    57 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## 
## Summary of sample sizes: 17659, 17660, 17660, 17658, 17660, 17661, ... 
## 
## Resampling results
## 
##   Accuracy   Kappa      Accuracy SD  Kappa SD   
##   0.8550195  0.8167284  0.007235691  0.009158566
## 
## 
</pre></div>
</div></div>

<p>The model has been fitted using 10-fold cross validation with five replicates. The out-of-sample accuracy is 0.855 meaning that the in-sample error rate is 1-0.855=0.145. The out of sample error rate is of course unknown, but I would expect it to be a little larger than 0.145.<p>

<p> Note that I get a lot of warnings when fitting the model because some of my predictor variables are colinear. I don't pay much attention to the warnings in this case, since my main concern is prediction. If I was interested in making inference on my predictor variables, I would look further into this.

<p>I now use the fitted model to predict the 20 observations from the test set.<p>
<div class="chunk" id="unnamed-chunk-5"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">pred.lda</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">predict</span><span class="hl std">(lda.fit, test)</span>
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: MASS
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl std">pred.lda</span>
</pre></div>
<div class="output"><pre class="knitr r">##  [1] B B B A A E D C A A B C B A E E A B B B
## Levels: A B C D E
</pre></div>
</div></div>

</body>
</html>
